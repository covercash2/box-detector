{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of model_maker_image_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "TUfAcER1oUS6"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# Image classification with TensorFlow Lite Model Maker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDABAblytltI"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/lite/tutorials/model_maker_image_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/tensorflow/tensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://tfhub.dev/\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub model</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m86-Nh4pMHqY"
      },
      "source": [
        "Model Maker library simplifies the process of adapting and converting a TensorFlow neural-network model to particular input data when deploying this model for on-device ML applications.\n",
        "\n",
        "This notebook shows an end-to-end example that utilizes this Model Maker library to illustrate the adaption and conversion of a commonly-used image classification model to classify flowers on a mobile device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flPAs5IDALDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eff9910-c0ae-445c-8cf1-c21a339de76c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jan 16 21:01:30 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcLF2PKkSbV3"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "To run this example, we first need to install several required packages, including Model Maker package that in GitHub [repo](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cv3K3oaksJv",
        "outputId": "18cae662-ad14-4f35-a7ac-fa629bea94e7"
      },
      "source": [
        "!pip install tflite-model-maker"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tflite-model-maker in /usr/local/lib/python3.6/dist-packages (0.2.4)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (0.1.95)\n",
            "Requirement already satisfied: flatbuffers==1.12 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (1.12)\n",
            "Requirement already satisfied: tflite-support==0.1.0rc4 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (0.1.0rc4)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (0.11.0)\n",
            "Requirement already satisfied: pillow>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (7.0.0)\n",
            "Requirement already satisfied: tensorflow-datasets>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (4.0.1)\n",
            "Requirement already satisfied: fire>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (0.3.1)\n",
            "Requirement already satisfied: librosa>=0.5 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (0.6.3)\n",
            "Requirement already satisfied: absl-py<0.11>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (1.19.5)\n",
            "Requirement already satisfied: tf-models-official==2.3.0 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (2.3.0)\n",
            "Requirement already satisfied: tensorflowjs>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (2.8.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (1.24.3)\n",
            "Requirement already satisfied: tensorflow>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (2.4.0)\n",
            "Requirement already satisfied: lxml>=4.6.1 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (4.6.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.6/dist-packages (from tflite-model-maker) (5.3.1)\n",
            "Requirement already satisfied: pybind11>=2.4 in /usr/local/lib/python3.6/dist-packages (from tflite-support==0.1.0rc4->tflite-model-maker) (2.6.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub>=0.8.0->tflite-model-maker) (3.12.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.16.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.26.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (4.1.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (20.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (4.41.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (1.1.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.8)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.1.5)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5->tflite-model-maker) (2.1.9)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5->tflite-model-maker) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5->tflite-model-maker) (0.2.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5->tflite-model-maker) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5->tflite-model-maker) (1.0.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5->tflite-model-maker) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5->tflite-model-maker) (0.48.0)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (7.0.0)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.21.0)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (0.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (3.2.2)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.1.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.6/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (4.5.1.48)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (0.4.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (0.8.3)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.6/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.5.10)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.7.12)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.1.5)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (0.29.21)\n",
            "Requirement already satisfied: h5py<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs>=2.4.0->tflite-model-maker) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tflite-model-maker) (3.3.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tflite-model-maker) (2.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tflite-model-maker) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tflite-model-maker) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tflite-model-maker) (3.7.4.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tflite-model-maker) (0.36.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tflite-model-maker) (0.2.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tflite-model-maker) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tflite-model-maker) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tflite-model-maker) (0.3.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tflite-model-maker) (1.32.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-hub>=0.8.0->tflite-model-maker) (51.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets>=2.1.0->tflite-model-maker) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets>=2.1.0->tflite-model-maker) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets>=2.1.0->tflite-model-maker) (3.0.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets>=2.1.0->tflite-model-maker) (1.52.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets>=2.1.0->tflite-model-maker) (3.4.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa>=0.5->tflite-model-maker) (0.31.0)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker) (0.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tf-models-official==2.3.0->tflite-model-maker) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tf-models-official==2.3.0->tflite-model-maker) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tf-models-official==2.3.0->tflite-model-maker) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tf-models-official==2.3.0->tflite-model-maker) (0.10.0)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-official==2.3.0->tflite-model-maker) (2.7.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (4.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (1.17.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->tf-models-official==2.3.0->tflite-model-maker) (2018.9)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tflite-model-maker) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tflite-model-maker) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tflite-model-maker) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tflite-model-maker) (1.0.1)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker) (1.16.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (1.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (4.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->tflite-model-maker) (3.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tflite-model-maker) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tflite-model-maker) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx1HGRoFQ54j"
      },
      "source": [
        "Import the required packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtxiUeZEiXpt"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from tflite_model_maker import configs\n",
        "from tflite_model_maker import ExportFormat\n",
        "from tflite_model_maker import image_classifier\n",
        "from tflite_model_maker import ImageClassifierDataLoader\n",
        "from tflite_model_maker import model_spec\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKRaYHABpob5"
      },
      "source": [
        "## Simple End-to-End Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiZZ5DHXotaW"
      },
      "source": [
        "### Get the data path\n",
        "\n",
        "Let's get some images to play with this simple end-to-end example. Hundreds of images is a good start for Model Maker while more data could achieve better accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s3WRnBQCvOa",
        "outputId": "d7b4d58d-7f1f-4727-8c08-30a038855912"
      },
      "source": [
        "!unzip /content/upload.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/upload.zip\n",
            "replace labeled/magic_treasures/IMG_20210113_134355649.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: An\n",
            "  inflating: labeled/magic_treasures/IMG_20210113_134355649.jpg  \n",
            "  inflating: labeled/magic_treasures/IMG_20210113_134424682_HDR.jpg  \n",
            "  inflating: labeled/magic_treasures/IMG_20210113_134449862_HDR.jpg  \n",
            "  inflating: labeled/magic_treasures/IMG_20210113_134356927.jpg  \n",
            "  inflating: labeled/magic_treasures/IMG_20210113_134446614_HDR.jpg  \n",
            "  inflating: labeled/magic_treasures/IMG_20210113_134225092_HDR.jpg  \n",
            "  inflating: labeled/magic_treasures/IMG_20210113_134426226_HDR.jpg  \n",
            "  inflating: labeled/magic_treasures/IMG_20210113_134444852_HDR.jpg  \n",
            "  inflating: labeled/magic_treasures/IMG_20210113_134410328_HDR.jpg  \n",
            "  inflating: labeled/magic_treasures/IMG_20210113_134250512_HDR.jpg  \n",
            "  inflating: labeled/magic_treasures/IMG_20210113_134411029_HDR.jpg  \n",
            "  inflating: labeled/magic_treasures/IMG_20210113_134350786.jpg  \n",
            "  inflating: labeled/magic_treasures/IMG_20210113_134423710_HDR.jpg  \n",
            "  inflating: labeled/magic_treasures/IMG_20210113_134413190_HDR.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134355649.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134424682_HDR.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134226506_HDR.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134356927.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134423710_HDR_1.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134422640_HDR.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134358100.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134355649_1.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134225092_HDR.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134356927_1.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134426226_HDR.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134350786_1.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134422640_HDR_1.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134226506_HDR_1.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134414463_HDR.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134414463_HDR_1.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134350786.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134358100_1.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134349707.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134423710_HDR.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134222078_HDR.jpg  \n",
            "  inflating: labeled/froot_loops/IMG_20210113_134413190_HDR.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134217498_HDR.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134216637_HDR_1.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134226506_HDR.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134348021.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134356927.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134218801_HDR.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134230037_HDR_3.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134216637_HDR.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134230037_HDR.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134311640.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134309556.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134156610_HDR.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134245896_HDR.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134310560.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134358691_1.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134312590_1.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134230037_HDR_2.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134231142_HDR.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134311640_1.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134230037_HDR_1.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134312590.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134358691.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134314014.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134310560_1.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134217498_HDR_1.jpg  \n",
            "  inflating: labeled/great_value_cinnamon_crunch/IMG_20210113_134314014_1.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134355649.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134217498_HDR_3.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134347006.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134218801_HDR_1.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134348021.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134356927.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134218801_HDR.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134230037_HDR.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134358100.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134348757_1.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134356927_1.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134314014_2.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134410328_HDR.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134227381_HDR.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134358691_1.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134348757.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134358100_1.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134311640_1.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134312590.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134358691.jpg  \n",
            "  inflating: labeled/trix/IMG_20210113_134314014_1.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134151190_HDR_1.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134303881_3.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134151190_HDR_2.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134232192_HDR.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134305362.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134155480_HDR.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134153083_HDR.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134213388_HDR_1.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134211767_HDR_2.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134303881_1.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134213388_HDR_3.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134305362_3.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134153083_HDR_2.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134151190_HDR.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134213388_HDR.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134211767_HDR.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134154132_HDR_2.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134303881_2.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134153083_HDR_1.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134214414_HDR_1.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134214414_HDR.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134303881.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134242319_HDR.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134240517_HDR.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134303881_4.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134305362_1.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134151190_HDR_4.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134151190_HDR_3.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134211767_HDR_4.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134211767_HDR_1.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134213388_HDR_4.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134214414_HDR_2.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134214414_HDR_3.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134213388_HDR_2.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134305362_2.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134308469.jpg  \n",
            "  inflating: labeled/kellogs_frosted_flakes/IMG_20210113_134211767_HDR_3.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134312590_2.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134155480_HDR_1.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134216637_HDR_1.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134154132_HDR_1.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134155480_HDR_2.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134232192_HDR.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134305362.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134232192_HDR_1.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134155480_HDR.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134213388_HDR_1.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134303881_1.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134308469_3.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134231142_HDR_1.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134156610_HDR_1.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134216637_HDR.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134213388_HDR.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134154132_HDR.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134243028_HDR_1.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134308469_2.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134211767_HDR.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134309556.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134308469_1.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134156610_HDR.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134214414_HDR_1.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134214414_HDR.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134303881.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134242319_HDR.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134305362_1.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134308469_4.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134312590_1.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134231142_HDR.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134214414_HDR_2.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134243028_HDR.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134232192_HDR_2.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134312590.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134314014.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134308469.jpg  \n",
            "  inflating: labeled/great_value_frosted_flakes/IMG_20210113_134309556_1.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134156610_HDR_4.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134355649.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134217498_HDR_3.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134217498_HDR.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134155480_HDR_1.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134218801_HDR_1.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134216637_HDR_1.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134155480_HDR_2.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134232192_HDR.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134232192_HDR_1.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134155480_HDR.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134217498_HDR_2.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134218801_HDR.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134231142_HDR_1.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134156610_HDR_1.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134230037_HDR_3.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134216637_HDR.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134230037_HDR.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134231142_HDR_2.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134308469_1.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134156610_HDR.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134245896_HDR.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134214414_HDR_1.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134227381_HDR.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134214414_HDR.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134310560.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134231142_HDR_3.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134155480_HDR_3.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134230037_HDR_2.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134231142_HDR.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134216637_HDR_3.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134230037_HDR_1.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134156610_HDR_2.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134216637_HDR_4.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134314014.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134216637_HDR_2.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134310560_1.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134308469.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134217498_HDR_1.jpg  \n",
            "  inflating: labeled/cinnamon_toast_crunch/IMG_20210113_134156610_HDR_3.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134225092_HDR_2.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134413190_HDR_2.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134350786_2.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134226506_HDR.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134423710_HDR_1.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134248691_HDR.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134225092_HDR_3.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134413190_HDR_1.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134225092_HDR.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134426226_HDR.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134350786_1.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134225092_HDR_1.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134226506_HDR_1.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134222078_HDR_2.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134227381_HDR.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134414463_HDR.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134225092_HDR_4.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134227381_HDR_1.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134350786.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134349707.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134423710_HDR_2.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134222078_HDR.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134222078_HDR_3.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134222078_HDR_1.jpg  \n",
            "  inflating: labeled/lucky_charms/IMG_20210113_134413190_HDR.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "3jz5x0JoskPv"
      },
      "source": [
        "import os\n",
        "image_path = \"/content/labeled\"\n",
        "#image_path = \"content\"\n",
        "#image_path = tf.keras.utils.get_file(\n",
        "#      'flower_photos.tgz',\n",
        "#      'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "#      extract=True)\n",
        "#image_path = os.path.join(os.path.dirname(image_path), 'flower_photos')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a55MR6i6nuDm"
      },
      "source": [
        "You could replace `image_path` with your own image folders. As for uploading data to colab, you could find the upload button in the left sidebar shown in the image below with the red rectangle. Just have a try to upload a zip file and unzip it. The root file path is the current path.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/download.tensorflow.org/models/tflite/screenshots/model_maker_image_classification.png\" alt=\"Upload File\" width=\"800\" hspace=\"100\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNRNv_mloS89"
      },
      "source": [
        "If you prefer not to upload your images to the cloud, you could try to run the library locally following the [guide](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker) in GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-VDriAdsowu"
      },
      "source": [
        "### Run the example\n",
        "The example just consists of 4 lines of code as shown below, each of which representing one step of the overall process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ahtcO86tZBL"
      },
      "source": [
        "Step 1.   Load input data specific to an on-device ML app. Split it to training data and testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lANoNS_gtdH1",
        "outputId": "aabb4cca-5b94-4cde-c0c7-6ea6b80343fd"
      },
      "source": [
        "data = ImageClassifierDataLoader.from_folder(image_path)\n",
        "train_data, test_data = data.split(0.9)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Load image with size: 223, num_label: 8, labels: cinnamon_toast_crunch, froot_loops, great_value_cinnamon_crunch, great_value_frosted_flakes, kellogs_frosted_flakes, lucky_charms, magic_treasures, trix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_9IWyIztuRF"
      },
      "source": [
        "Step 2. Customize the TensorFlow model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRXMZbrwtyRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f909db36-e176-4fda-dc33-ed4de641bc00"
      },
      "source": [
        "model = image_classifier.create(train_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Retraining the models...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hub_keras_layer_v1v2 (HubKer (None, 1280)              3413024   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 10248     \n",
            "=================================================================\n",
            "Total params: 3,423,272\n",
            "Trainable params: 10,248\n",
            "Non-trainable params: 3,413,024\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "6/6 [==============================] - 14s 996ms/step - loss: 2.3883 - accuracy: 0.0840\n",
            "Epoch 2/5\n",
            "6/6 [==============================] - 7s 1s/step - loss: 1.7100 - accuracy: 0.4294\n",
            "Epoch 3/5\n",
            "6/6 [==============================] - 7s 1s/step - loss: 1.1278 - accuracy: 0.8114\n",
            "Epoch 4/5\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.8270 - accuracy: 0.9195\n",
            "Epoch 5/5\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.7007 - accuracy: 0.9721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxU2fDr-t2Ya"
      },
      "source": [
        "Step 3. Evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQr02VxJt6Cs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e0bed4-d87e-42d7-e9a8-e5046d63a056"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 4s 4s/step - loss: 0.5680 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVZw9zU8t84y"
      },
      "source": [
        "Step 4.  Export to TensorFlow Lite model.\n",
        "\n",
        "Here, we export TensorFlow Lite model with [metadata](https://www.tensorflow.org/lite/convert/metadata) which provides a standard for model descriptions. The label file is embedded in metadata.\n",
        "\n",
        "You could download it in the left sidebar same as the uploading part for your own use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb-eIzfluCoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c464a0d-eb21-4558-9974-c0901bd9d32a"
      },
      "source": [
        "model.export(export_dir='.')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpe05zqhcn/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpe05zqhcn/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmp3a3kub17/labels.txt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmp3a3kub17/labels.txt.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyju1qc_v-wy"
      },
      "source": [
        "After this simple 4 steps, we could further use TensorFlow Lite model file in on-device applications like in [image classification](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification) reference app."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SHuqYIYBdxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3092bd-2d09-4dda-c1eb-ca2f91647919"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9WQs27gBpNG"
      },
      "source": [
        "!cp /content/model.tflite /content/drive/MyDrive/models/cereal_model.tflite"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1QG32ivs9lF"
      },
      "source": [
        "## Detailed Process\n",
        "\n",
        "Currently, we support several models such as  EfficientNet-Lite* models, MobileNetV2, ResNet50 as pre-trained models for image classification. But it is very flexible to add new pre-trained models to this library with just a few lines of code.\n",
        "\n",
        "\n",
        "The following walks through this end-to-end example step by step to show more detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygEncJxtl-nQ"
      },
      "source": [
        "### Step 1: Load Input Data Specific to an On-device ML App\n",
        "\n",
        "The flower dataset contains 3670 images belonging to 5 classes. Download the archive version of the dataset and untar it.\n",
        "\n",
        "The dataset has the following directory structure:\n",
        "\n",
        "<pre>\n",
        "<b>flower_photos</b>\n",
        "|__ <b>daisy</b>\n",
        "    |______ 100080576_f52e8ee070_n.jpg\n",
        "    |______ 14167534527_781ceb1b7a_n.jpg\n",
        "    |______ ...\n",
        "|__ <b>dandelion</b>\n",
        "    |______ 10043234166_e6dd915111_n.jpg\n",
        "    |______ 1426682852_e62169221f_m.jpg\n",
        "    |______ ...\n",
        "|__ <b>roses</b>\n",
        "    |______ 102501987_3cdb8e5394_n.jpg\n",
        "    |______ 14982802401_a3dfb22afb.jpg\n",
        "    |______ ...\n",
        "|__ <b>sunflowers</b>\n",
        "    |______ 12471791574_bb1be83df4.jpg\n",
        "    |______ 15122112402_cafa41934f.jpg\n",
        "    |______ ...\n",
        "|__ <b>tulips</b>\n",
        "    |______ 13976522214_ccec508fe7.jpg\n",
        "    |______ 14487943607_651e8062a1_m.jpg\n",
        "    |______ ...\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tOfUr2KlgpU"
      },
      "source": [
        "image_path = tf.keras.utils.get_file(\n",
        "      'flower_photos.tgz',\n",
        "      'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "      extract=True)\n",
        "image_path = os.path.join(os.path.dirname(image_path), 'flower_photos')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E051HBUM5owi"
      },
      "source": [
        "Use `ImageClassifierDataLoader` class to load data.\n",
        "\n",
        "As for `from_folder()` method, it could load data from the folder. It assumes that the image data of the same class are in the same subdirectory and the subfolder name is the class name. Currently, JPEG-encoded images and PNG-encoded images are supported."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_fOlZsklmlL"
      },
      "source": [
        "data = ImageClassifierDataLoader.from_folder(image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u501eT4koURB"
      },
      "source": [
        "Split it to training data (80%), validation data (10%, optional) and testing data (10%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY4UU5SUobtJ"
      },
      "source": [
        "train_data, rest_data = data.split(0.8)\n",
        "validation_data, test_data = rest_data.split(0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9_MYPie3EMO"
      },
      "source": [
        "Show 25 image examples with labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih4Wx44I482b"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i, (image, label) in enumerate(data.gen_dataset().unbatch().take(25)):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
        "  plt.xlabel(data.index_to_label[label.numpy()])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWuoensX4vDA"
      },
      "source": [
        "### Step 2: Customize the TensorFlow Model\n",
        "\n",
        "Create a custom image classifier model based on the loaded data. The default model is EfficientNet-Lite0.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvYSUuJY3QxR"
      },
      "source": [
        "model = image_classifier.create(train_data, validation_data=validation_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JFOKWnH9x8_"
      },
      "source": [
        "Have a look at the detailed model structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNXAfjl192dC"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP5FPk_tOxoZ"
      },
      "source": [
        "### Step 3: Evaluate the Customized Model\n",
        "\n",
        "Evaluate the result of the model, get the loss and accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8c2ZQ0J3Riy"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZCrYOWoCt05"
      },
      "source": [
        "We could plot the predicted results in 100 test images. Predicted labels with red color are the wrong predicted results while others are correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9O9Kx7nDQWD"
      },
      "source": [
        "# A helper function that returns 'red'/'black' depending on if its two input\n",
        "# parameter matches or not.\n",
        "def get_label_color(val1, val2):\n",
        "  if val1 == val2:\n",
        "    return 'black'\n",
        "  else:\n",
        "    return 'red'\n",
        "\n",
        "# Then plot 100 test images and their predicted labels.\n",
        "# If a prediction result is different from the label provided label in \"test\"\n",
        "# dataset, we will highlight it in red color.\n",
        "plt.figure(figsize=(20, 20))\n",
        "predicts = model.predict_top_k(test_data)\n",
        "for i, (image, label) in enumerate(test_data.gen_dataset().unbatch().take(100)):\n",
        "  ax = plt.subplot(10, 10, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
        "\n",
        "  predict_label = predicts[i][0][0]\n",
        "  color = get_label_color(predict_label,\n",
        "                          test_data.index_to_label[label.numpy()])\n",
        "  ax.xaxis.label.set_color(color)\n",
        "  plt.xlabel('Predicted: %s' % predict_label)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3H0rkbLUZAG"
      },
      "source": [
        "If the accuracy doesn't meet the app requirement, one could refer to [Advanced Usage](#scrollTo=zNDBP2qA54aK) to explore alternatives such as changing to a larger model, adjusting re-training parameters etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeHoGAceO2xV"
      },
      "source": [
        "### Step 4: Export to TensorFlow Lite Model\n",
        "\n",
        "Convert the existing model to TensorFlow Lite model format with  [metadata](https://www.tensorflow.org/lite/convert/metadata). The default TFLite filename is `model.tflite`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im6wA9lK3TQB"
      },
      "source": [
        "model.export(export_dir='.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROS2Ay2jMPCl"
      },
      "source": [
        "See [example applications and guides of image classification](https://www.tensorflow.org/lite/models/image_classification/overview#example_applications_and_guides) for more details about how to integrate the TensorFlow Lite model into mobile apps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "habFnvRxxQ4A"
      },
      "source": [
        "The allowed export formats can be one or a list of the following:\n",
        "\n",
        "*   `ExportFormat.TFLITE`\n",
        "*   `ExportFormat.LABEL`\n",
        "*   `ExportFormat.SAVED_MODEL`\n",
        "\n",
        "By default, it just exports TensorFlow Lite model with metadata. You can also selectively export different files. For instance, exporting only the label file as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvxWsOTmKG4P"
      },
      "source": [
        "model.export(export_dir='.', export_format=ExportFormat.LABEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4jQaxyT5_KV"
      },
      "source": [
        "You can also evaluate the tflite model with the `evaluate_tflite` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1YoPX5wOK-u"
      },
      "source": [
        "model.evaluate_tflite('model.tflite', test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNDBP2qA54aK"
      },
      "source": [
        "## Advanced Usage\n",
        "\n",
        "The `create` function is the critical part of this library. It uses transfer learning with a pretrained model similar to the [tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning).\n",
        "\n",
        "The `create`function contains the following steps:\n",
        "\n",
        "1.   Split the data into training, validation, testing data according to parameter `validation_ratio` and `test_ratio`. The default value of `validation_ratio` and `test_ratio` are `0.1` and `0.1`.\n",
        "2.   Download a [Image Feature Vector](https://www.tensorflow.org/hub/common_signatures/images#image_feature_vector) as the base model from TensorFlow Hub. The default pre-trained model is  EfficientNet-Lite0.\n",
        "3.   Add a classifier head with a Dropout Layer with `dropout_rate` between head layer and pre-trained model. The default `dropout_rate` is the default `dropout_rate` value from [make_image_classifier_lib](https://github.com/tensorflow/hub/blob/master/tensorflow_hub/tools/make_image_classifier/make_image_classifier_lib.py#L55) by TensorFlow Hub.\n",
        "4.   Preprocess the raw input data. Currently, preprocessing steps including normalizing the value of each image pixel to model input scale and resizing it to model input size.   EfficientNet-Lite0 have the input scale `[0, 1]` and the input image size `[224, 224, 3]`.\n",
        "5.   Feed the data into the classifier model. By default, the training parameters such as training epochs, batch size, learning rate, momentum are the default values from [make_image_classifier_lib](https://github.com/tensorflow/hub/blob/master/tensorflow_hub/tools/make_image_classifier/make_image_classifier_lib.py#L55) by TensorFlow Hub. Only the classifier head is trained.\n",
        "\n",
        "\n",
        "In this section, we describe several advanced topics, including switching to a different image classification model, changing the training hyperparameters etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc4Jk8TvBQfm"
      },
      "source": [
        "## Post-training quantization on the TensorFLow Lite model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD8BOYrHBiDt"
      },
      "source": [
        "[Post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) is a conversion technique that can reduce model size and inference latency, while also improving CPU and hardware accelerator latency, with little degradation in model accuracy. Thus, it's widely used to optimize the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyIo0d5TCzE2"
      },
      "source": [
        "Model Maker supports multiple post-training quantization options. Let's take full integer quantization as an instance. First, define the quantization config to enforce full integer quantization for all ops including the input and output. The input type and output type are `uint8` by default. You may also change them to other types like `int8` by setting `inference_input_type` and `inference_output_type` in config."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8hL2mstCxQl"
      },
      "source": [
        "config = configs.QuantizationConfig.create_full_integer_quantization(representative_data=test_data, is_integer_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1gzx_rmFMOA"
      },
      "source": [
        "Then we export TensorFlow Lite model with such configuration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTJzFQnJFMjr"
      },
      "source": [
        "model.export(export_dir='.', tflite_filename='model_quant.tflite', quantization_config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Safo0e40wKZW"
      },
      "source": [
        "In Colab, you can download the model named `model_quant.tflite` from the left sidebar, same as the uploading part mentioned above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4kiTJtZ_sDm"
      },
      "source": [
        "## Change the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "794vgj6ud7Ep"
      },
      "source": [
        "### Change to the model that's supported in this library.\n",
        "\n",
        "This library supports  EfficientNet-Lite models, MobileNetV2, ResNet50 by now. [EfficientNet-Lite](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite) are a family of image classification models that could achieve state-of-art accuracy and suitable for Edge devices. The default model is EfficientNet-Lite0.\n",
        "\n",
        "We could switch model to MobileNetV2 by just setting parameter `model_spec` to  `mobilenet_v2_spec` in `create` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JKsJ6-P6ae1"
      },
      "source": [
        "model = image_classifier.create(train_data, model_spec=model_spec.mobilenet_v2_spec, validation_data=validation_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm_B1Wv08AxR"
      },
      "source": [
        "Evaluate the newly retrained MobileNetV2 model to see the accuracy and loss in testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB2Go3HW8X7_"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAciGzVWtmWp"
      },
      "source": [
        "### Change to the model in TensorFlow Hub\n",
        "\n",
        "Moreover, we could also switch to other new models that inputs an image and outputs a feature vector with TensorFlow Hub format.\n",
        "\n",
        "As [Inception V3](https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1) model as an example, we could define `inception_v3_spec` which is an object of `ImageModelSpec` and contains the specification of the Inception V3 model.\n",
        "\n",
        "We need to specify the model name `name`, the url of the TensorFlow Hub model `uri`. Meanwhile, the default value of `input_image_shape` is `[224, 224]`. We need to change it to `[299, 299]` for Inception V3 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdiMF2WMfAR4"
      },
      "source": [
        "inception_v3_spec = model_spec.ImageModelSpec(\n",
        "    uri='https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1')\n",
        "inception_v3_spec.input_image_shape = [299, 299]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_GGIoXZCs5F"
      },
      "source": [
        "Then, by setting parameter `model_spec` to `inception_v3_spec` in `create` method, we could retrain the Inception V3 model.\n",
        "\n",
        "The remaining steps are exactly same and we could get a customized InceptionV3 TensorFlow Lite model in the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhZ5IRKdeex3"
      },
      "source": [
        "### Change your own custom model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svTjlZhrCrcV"
      },
      "source": [
        "If we'd like to use the custom model that's not in TensorFlow Hub, we should create and export [ModelSpec](https://www.tensorflow.org/hub/api_docs/python/hub/ModuleSpec) in TensorFlow Hub.\n",
        "\n",
        "Then start to define `ImageModelSpec` object like the process above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M9bn703AHt2"
      },
      "source": [
        "## Change the training hyperparameters\n",
        "We could also change the training hyperparameters like `epochs`, `dropout_rate` and `batch_size` that could affect the model accuracy. The model parameters you can adjust are:\n",
        "\n",
        "\n",
        "*   `epochs`: more epochs could achieve better accuracy until it converges but training for too many epochs may lead to overfitting.\n",
        "*   `dropout_rate`: The rate for dropout, avoid overfitting. None by default.\n",
        "*   `batch_size`: number of samples to use in one training step.  None by default.\n",
        "*   `validation_data`: Validation data. If None, skips validation process. None by default.\n",
        "*   `train_whole_model`: If true, the Hub module is trained together with the classification layer on top. Otherwise, only train the top classification layer. None by default.\n",
        "*   `learning_rate`: Base learning rate. None by default.\n",
        "*   `momentum`: a Python float forwarded to the optimizer. Only used when\n",
        "      `use_hub_library` is True. None by default.\n",
        "*   `shuffle`: Boolean, whether the data should be shuffled. False by default.\n",
        "*   `use_augmentation`: Boolean, use data augmentation for preprocessing. False by default.\n",
        "*   `use_hub_library`: Boolean, use `make_image_classifier_lib` from tensorflow hub to retrain the model. This training pipeline could achieve better performance for complicated dataset with many categories. True by default. \n",
        "*   `warmup_steps`: Number of warmup steps for warmup schedule on learning rate. If None, the default warmup_steps is used which is the total training steps in two epochs. Only used when `use_hub_library` is False. None by default.\n",
        "*   `model_dir`: Optional, the location of the model checkpoint files. Only used when `use_hub_library` is False. None by default.\n",
        "\n",
        "Parameters which are None by default like `epochs` will get the concrete default parameters in [make_image_classifier_lib](https://github.com/tensorflow/hub/blob/02ab9b7d3455e99e97abecf43c5d598a5528e20c/tensorflow_hub/tools/make_image_classifier/make_image_classifier_lib.py#L54) from TensorFlow Hub library or  [train_image_classifier_lib](https://github.com/tensorflow/examples/blob/f0260433d133fd3cea4a920d1e53ecda07163aee/tensorflow_examples/lite/model_maker/core/task/train_image_classifier_lib.py#L61).\n",
        "\n",
        "For example, we could train with more epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3k7mhH54QcK"
      },
      "source": [
        "model = image_classifier.create(train_data, validation_data=validation_data, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaYBQymQDsXU"
      },
      "source": [
        "Evaluate the newly retrained model with 10 training epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VafIYpKWD4Sw"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}